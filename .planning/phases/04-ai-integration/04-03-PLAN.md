---
phase: 04-ai-integration
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - package.json
  - src/runtimes/ai/runtime.ts
  - src/runtimes/ai/index.ts
  - src/runtimes/index.ts
autonomous: true
user_setup:
  - service: openrouter
    why: "AI model API access"
    env_vars:
      - name: OPENROUTER_API_KEY
        source: "https://openrouter.ai/settings/keys -> Create Key"

must_haves:
  truths:
    - AI runtime calls OpenRouter via pi-ai complete() with tool-based structured output
    - System and user prompts support template expressions (resolved before sending)
    - Output is validated with Zod schema after extraction from tool call
    - Validation failure triggers retry with error feedback in new user message
    - Rate limit (429) triggers exponential backoff with jitter
    - Maximum 3 retries for validation failures (configurable)
    - 60 second default timeout with AbortSignal
  artifacts:
    - src/runtimes/ai/runtime.ts
    - src/runtimes/ai/index.ts
  key_links:
    - aiRuntime registered in runtimeRegistry as 'ai'
    - runtime imports from ./types, ./errors, ./retry, ./schema-dsl
    - runtime uses pi-ai complete() not stream()
---

<objective>
Create the AI runtime that calls OpenRouter via pi-ai with structured output validation.

Purpose: Enable AI nodes in workflows to call LLMs, validate responses against schemas, and automatically retry on validation failures. This is the core AI integration that makes FlowScript AI-powered.

Output: Complete `ai` runtime registered in the global registry, ready for workflow execution.
</objective>

<execution_context>
@/Users/narcisbrindusescu/.claude/looppool/workflows/execute-plan.md
@/Users/narcisbrindusescu/.claude/looppool/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-ai-integration/04-CONTEXT.md
@.planning/phases/04-ai-integration/04-RESEARCH.md
@.planning/phases/04-ai-integration/04-01-SUMMARY.md
@.planning/phases/04-ai-integration/04-02-SUMMARY.md

<!-- Runtime patterns from Phase 3 -->
@src/runtimes/types.ts
@src/runtimes/registry.ts
@src/runtimes/http/source.ts

<!-- Execution context for template resolution -->
@src/execution/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install pi-ai dependency</name>
  <files>package.json</files>
  <action>
Install the pi-ai library:

```bash
bun install @anthropic-ai/sdk@^0.39.0
```

Note: Research indicated @mariozechner/pi-ai but the actual package name needs verification. If pi-ai is not available on npm, use the direct OpenRouter API approach with fetch as a fallback. Check the package exists first:

```bash
# Verify package exists
bun info @mariozechner/pi-ai 2>/dev/null || echo "Package not found"
```

If pi-ai is not on npm, implement direct OpenRouter API calls using fetch with tool calling support (OpenAI-compatible API).
  </action>
  <verify>bun install && bun run typecheck</verify>
  <done>AI package installed and importable</done>
</task>

<task type="auto">
  <name>Task 2: Create AI runtime implementation</name>
  <files>src/runtimes/ai/runtime.ts</files>
  <action>
Create `src/runtimes/ai/runtime.ts` implementing the AI runtime:

```typescript
/**
 * AI Runtime for FlowScript
 *
 * Calls AI models via OpenRouter with structured output validation.
 * Uses tool calling to force JSON output matching user-defined schemas.
 */

import { z } from 'zod';
import type { NodeRuntime, ExecutionParams } from '../types.ts';
import type { AINodeConfig, AIResult, AIErrorCode } from './types.ts';
import { AIError, SchemaValidationError, isRateLimitError } from './errors.ts';
import { calculateBackoffMs, sleep, buildRetryPrompt } from './retry.ts';
import { parseSchemaDSL } from './schema-dsl.ts';
import { evaluateTemplateInContext } from '../../execution/index.ts';
import type { ExecutionState } from '../../execution/types.ts';

// ============================================================================
// OpenRouter Configuration
// ============================================================================

const OPENROUTER_BASE_URL = 'https://openrouter.ai/api/v1';
const DEFAULT_MAX_TOKENS = 4096;
const DEFAULT_MAX_RETRIES = 3;
const DEFAULT_TIMEOUT = 60000;

// ============================================================================
// Helper Types
// ============================================================================

interface OpenRouterRequest {
  model: string;
  messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }>;
  tools?: Array<{
    type: 'function';
    function: {
      name: string;
      description: string;
      parameters: object;
    };
  }>;
  tool_choice?: { type: 'function'; function: { name: string } };
  max_tokens?: number;
}

interface OpenRouterResponse {
  id: string;
  choices: Array<{
    message: {
      role: string;
      content?: string;
      tool_calls?: Array<{
        id: string;
        type: 'function';
        function: {
          name: string;
          arguments: string;
        };
      }>;
    };
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

// ============================================================================
// AI Runtime Implementation
// ============================================================================

/**
 * AI Runtime configuration from node attributes.
 */
interface AIRuntimeConfig {
  /** OpenRouter model ID (e.g., "anthropic/claude-3.5-sonnet") */
  model: string;
  /** Output schema DSL (e.g., "{name: string, tags: string[]}") */
  'output-schema'?: string;
  /** Maximum output tokens */
  'max-tokens'?: string;
  /** Maximum retries on validation failure */
  'max-retries'?: string;
  /** Request timeout in milliseconds */
  timeout?: string;
}

/**
 * AI Runtime - calls OpenRouter with structured output validation.
 *
 * @example
 * ```xml
 * <ai id="analyze"
 *   model="anthropic/claude-3.5-sonnet"
 *   output-schema="{sentiment: string, score: number}"
 *   max-tokens="1024">
 *   <system>You are a sentiment analyzer.</system>
 *   <user>Analyze: {{input.text}}</user>
 * </ai>
 * ```
 */
class AIRuntime implements NodeRuntime<AIRuntimeConfig, unknown, unknown> {
  readonly type = 'ai';

  async execute(params: ExecutionParams<AIRuntimeConfig, unknown>): Promise<unknown> {
    const { node, input, config, state } = params;

    // Extract prompts from node children
    const systemPrompt = this.extractPrompt(node, 'system', state);
    const userPrompt = this.extractPrompt(node, 'user', state);

    if (!userPrompt) {
      throw new AIError('AI node requires a <user> prompt', 'API_ERROR', false);
    }

    // Parse configuration
    const model = config.model;
    if (!model) {
      throw new AIError('AI node requires model attribute', 'API_ERROR', false);
    }

    const maxTokens = config['max-tokens']
      ? parseInt(config['max-tokens'], 10)
      : DEFAULT_MAX_TOKENS;
    const maxRetries = config['max-retries']
      ? parseInt(config['max-retries'], 10)
      : DEFAULT_MAX_RETRIES;
    const timeout = config.timeout
      ? parseInt(config.timeout, 10)
      : DEFAULT_TIMEOUT;

    // Parse output schema if provided
    let outputSchema: z.ZodType | undefined;
    if (config['output-schema']) {
      outputSchema = parseSchemaDSL(config['output-schema']);
    }

    // Get API key from secrets
    const apiKey = state.secrets?.OPENROUTER_API_KEY;
    if (!apiKey) {
      throw new AIError(
        'Missing OPENROUTER_API_KEY in secrets',
        'API_ERROR',
        false
      );
    }

    // Execute with retry logic
    return this.executeWithRetry({
      model,
      systemPrompt,
      userPrompt,
      outputSchema,
      maxTokens,
      maxRetries,
      timeout,
      apiKey,
      input,
    });
  }

  /**
   * Extract and resolve prompt from node children.
   */
  private extractPrompt(
    node: ExecutionParams['node'],
    type: 'system' | 'user',
    state: ExecutionState
  ): string | undefined {
    // Find child element with matching tag name
    const children = (node as any).children || [];
    const promptNode = children.find(
      (child: any) => child.tagName?.toLowerCase() === type
    );

    if (!promptNode) {
      return undefined;
    }

    // Get text content and resolve templates
    const rawContent = promptNode.textContent || promptNode.content || '';
    return evaluateTemplateInContext(rawContent, state);
  }

  /**
   * Execute AI request with retry logic for validation and rate limits.
   */
  private async executeWithRetry(params: {
    model: string;
    systemPrompt?: string;
    userPrompt: string;
    outputSchema?: z.ZodType;
    maxTokens: number;
    maxRetries: number;
    timeout: number;
    apiKey: string;
    input: unknown;
  }): Promise<unknown> {
    const {
      model,
      systemPrompt,
      outputSchema,
      maxTokens,
      maxRetries,
      timeout,
      apiKey,
    } = params;

    let currentUserPrompt = params.userPrompt;
    let lastError: Error | null = null;
    let totalRetries = 0;

    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const result = await this.callOpenRouter({
          model,
          systemPrompt,
          userPrompt: currentUserPrompt,
          outputSchema,
          maxTokens,
          timeout,
          apiKey,
        });

        // If we have a schema, validate the output
        if (outputSchema) {
          const parsed = outputSchema.safeParse(result);
          if (!parsed.success) {
            throw new SchemaValidationError(
              'Output does not match schema',
              result,
              JSON.stringify(parsed.error.format(), null, 2)
            );
          }
          return parsed.data;
        }

        return result;
      } catch (error) {
        lastError = error as Error;

        // Handle schema validation errors with retry
        if (error instanceof SchemaValidationError && attempt < maxRetries) {
          totalRetries++;
          currentUserPrompt = buildRetryPrompt(
            params.userPrompt,
            error.failedOutput,
            error.validationMessage
          );
          continue;
        }

        // Handle rate limiting with exponential backoff
        if (isRateLimitError(error) && attempt < maxRetries) {
          totalRetries++;
          const backoffMs = calculateBackoffMs(attempt);
          await sleep(backoffMs);
          continue;
        }

        throw error;
      }
    }

    throw lastError || new AIError('AI execution failed', 'API_ERROR', false);
  }

  /**
   * Make the actual OpenRouter API call.
   */
  private async callOpenRouter(params: {
    model: string;
    systemPrompt?: string;
    userPrompt: string;
    outputSchema?: z.ZodType;
    maxTokens: number;
    timeout: number;
    apiKey: string;
  }): Promise<unknown> {
    const { model, systemPrompt, userPrompt, outputSchema, maxTokens, timeout, apiKey } = params;

    // Build messages
    const messages: OpenRouterRequest['messages'] = [];
    if (systemPrompt) {
      messages.push({ role: 'system', content: systemPrompt });
    }
    messages.push({ role: 'user', content: userPrompt });

    // Build request body
    const requestBody: OpenRouterRequest = {
      model,
      messages,
      max_tokens: maxTokens,
    };

    // If we have a schema, use tool calling to force structured output
    if (outputSchema) {
      const jsonSchema = z.toJSONSchema(outputSchema);

      requestBody.tools = [
        {
          type: 'function',
          function: {
            name: 'respond',
            description: 'Provide the structured response matching the required schema',
            parameters: jsonSchema as object,
          },
        },
      ];

      // Force the model to use the tool
      requestBody.tool_choice = {
        type: 'function',
        function: { name: 'respond' },
      };
    }

    // Make the request
    const response = await fetch(`${OPENROUTER_BASE_URL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${apiKey}`,
        'HTTP-Referer': 'https://flowscript.dev',
        'X-Title': 'FlowScript',
      },
      body: JSON.stringify(requestBody),
      signal: AbortSignal.timeout(timeout),
    });

    // Handle HTTP errors
    if (!response.ok) {
      const errorBody = await response.text();

      if (response.status === 429) {
        throw new AIError(
          `Rate limited: ${response.statusText}`,
          'RATE_LIMIT',
          true
        );
      }

      throw new AIError(
        `OpenRouter API error: ${response.status} ${response.statusText}`,
        'API_ERROR',
        response.status >= 500
      );
    }

    const data: OpenRouterResponse = await response.json();

    // Extract result
    const choice = data.choices[0];
    if (!choice) {
      throw new AIError('No response from model', 'API_ERROR', false);
    }

    // If using tool calling, extract from tool call arguments
    if (outputSchema && choice.message.tool_calls?.[0]) {
      const toolCall = choice.message.tool_calls[0];
      try {
        return JSON.parse(toolCall.function.arguments);
      } catch (e) {
        throw new SchemaValidationError(
          'Failed to parse tool call arguments as JSON',
          toolCall.function.arguments,
          (e as Error).message
        );
      }
    }

    // Otherwise return text content
    if (choice.message.content) {
      // Try to parse as JSON if no schema (for backwards compatibility)
      try {
        return JSON.parse(choice.message.content);
      } catch {
        return choice.message.content;
      }
    }

    throw new AIError('Empty response from model', 'API_ERROR', false);
  }
}

/**
 * AI runtime instance.
 */
export const aiRuntime = new AIRuntime();
```
  </action>
  <verify>bun run typecheck</verify>
  <done>AIRuntime class implemented with tool-based structured output, retry logic, and rate limit handling</done>
</task>

<task type="auto">
  <name>Task 3: Create AI runtime barrel export and register</name>
  <files>src/runtimes/ai/index.ts, src/runtimes/index.ts</files>
  <action>
1. Create `src/runtimes/ai/index.ts`:

```typescript
/**
 * AI Runtime Module for FlowScript
 *
 * Exports AI runtime components and registers the runtime.
 */

// Export types
export type { AINodeConfig, AIResult, AIErrorCode } from './types.ts';

// Export errors
export { AIError, SchemaValidationError, isRateLimitError } from './errors.ts';

// Export retry utilities
export { calculateBackoffMs, sleep, buildRetryPrompt } from './retry.ts';

// Export schema DSL
export { parseSchemaDSL, SchemaDSLError } from './schema-dsl.ts';

// Export and register runtime
export { aiRuntime } from './runtime.ts';

// Register on import
import { runtimeRegistry } from '../registry.ts';
import { aiRuntime } from './runtime.ts';

runtimeRegistry.register(aiRuntime);
```

2. Update `src/runtimes/index.ts` to include AI runtime:

Add import for AI runtime module (this triggers registration):

```typescript
// At the end of existing imports
import './ai/index.ts';
```

Ensure the file exports:
- All existing exports (types, errors, registry functions)
- Add AI-specific exports if useful for external consumers
  </action>
  <verify>bun run typecheck</verify>
  <done>AI runtime exported and registered in global registry</done>
</task>

</tasks>

<verification>
```bash
# Type check passes
bun run typecheck

# Registry includes AI runtime
echo "import { runtimeRegistry } from './src/runtimes/index.ts';
console.log('Registered runtimes:', runtimeRegistry.list());
console.log('Has AI:', runtimeRegistry.has('ai'));" | bun run -

# Schema DSL to runtime integration
echo "import { parseSchemaDSL } from './src/runtimes/ai/schema-dsl.ts';
import { z } from 'zod';
const schema = parseSchemaDSL('{name: string, score: number}');
const jsonSchema = z.toJSONSchema(schema);
console.log('JSON Schema generated:', !!jsonSchema.properties);" | bun run -

# All tests pass
bun test
```
</verification>

<success_criteria>
- [ ] @anthropic-ai/sdk or equivalent AI package installed
- [ ] AIRuntime implements NodeRuntime interface
- [ ] aiRuntime.type === 'ai'
- [ ] Runtime extracts system/user prompts from node children
- [ ] Templates in prompts are resolved via evaluateTemplateInContext
- [ ] Output schema parsed via parseSchemaDSL and validated with Zod
- [ ] Tool calling forces structured JSON output
- [ ] Validation failure retries with error feedback in prompt
- [ ] Rate limit (429) triggers exponential backoff with jitter
- [ ] AI runtime registered in runtimeRegistry
- [ ] `bun run typecheck` passes
- [ ] `bun test` passes
</success_criteria>

<output>
After completion, create `.planning/phases/04-ai-integration/04-03-SUMMARY.md`
</output>
